----------------------------------------------
1th fold cross-validation
integrating files of  ../control_vs_heme_ft_cv/cv1/train/control/
number of files: 84096
size of feature vector: 2048
size of feature matrix: (84096, 2048)
size of label vector: (84096,)
size of training data of control class:(84096, 2048)
number of training data points of control:84096
integrating files of  ../control_vs_heme_ft_cv/cv1/train/heme/
number of files: 25776
size of feature vector: 2048
size of feature matrix: (25776, 2048)
size of label vector: (25776,)
size of training data of heme class:(25776, 2048)
number of training data points of heme:25776
integrating files of  ../control_vs_heme_ft_cv/cv1/val/control/
number of files: 9312
size of feature vector: 2048
size of feature matrix: (9312, 2048)
size of label vector: (9312,)
size of val data of control class:(9312, 2048)
number of val data points of control:9312
integrating files of  ../control_vs_heme_ft_cv/cv1/val/heme/
number of files: 2832
size of feature vector: 2048
size of feature matrix: (2832, 2048)
size of label vector: (2832,)
size of val data of heme class:(2832, 2048)
number of val data points of heme:2832
shape of X_train: (109872, 2048)
shape of y_train: (109872,)
shape of X_val: (12144, 2048)
shape of y_val: (12144,)
training the MLP...
Iteration 1, loss = 0.47429521
Iteration 2, loss = 0.44557278
Iteration 3, loss = 0.44120655
Iteration 4, loss = 0.43833397
Iteration 5, loss = 0.43551370
Iteration 6, loss = 0.43419829
Iteration 7, loss = 0.43278913
Iteration 8, loss = 0.43009578
Iteration 9, loss = 0.42632415
Iteration 10, loss = 0.42371426
Iteration 11, loss = 0.42027005
Iteration 12, loss = 0.41895444
Iteration 13, loss = 0.41571547
Iteration 14, loss = 0.41294144
Iteration 15, loss = 0.41113909
Iteration 16, loss = 0.40773991
Iteration 17, loss = 0.40560510
Iteration 18, loss = 0.40484995
Iteration 19, loss = 0.40362066
Iteration 20, loss = 0.40075043
Iteration 21, loss = 0.39972223
Iteration 22, loss = 0.39684806
Iteration 23, loss = 0.39669580
Iteration 24, loss = 0.39414233
Iteration 25, loss = 0.39429296
Iteration 26, loss = 0.39158801
Iteration 27, loss = 0.39168440
Iteration 28, loss = 0.39100930
Iteration 29, loss = 0.39111426
Iteration 30, loss = 0.38846740
Iteration 31, loss = 0.38969332
Iteration 32, loss = 0.38744931
Iteration 33, loss = 0.38685113
Iteration 34, loss = 0.38692097
Iteration 35, loss = 0.38655656
Iteration 36, loss = 0.38372628
Iteration 37, loss = 0.38535178
Iteration 38, loss = 0.38242223
Iteration 39, loss = 0.38072433
Iteration 40, loss = 0.39488218
Iteration 41, loss = 0.39534527
Iteration 42, loss = 0.39272971
Iteration 43, loss = 0.39227651
Iteration 44, loss = 0.39164327
Iteration 45, loss = 0.39173075
Iteration 46, loss = 0.38949310
Iteration 47, loss = 0.38899500
Iteration 48, loss = 0.38339331
Iteration 49, loss = 0.37986351
Iteration 50, loss = 0.38016871
Iteration 51, loss = 0.37766177
Iteration 52, loss = 0.37780846
Iteration 53, loss = 0.37722010
Iteration 54, loss = 0.37831417
Iteration 55, loss = 0.37766245
Iteration 56, loss = 0.37573953
Iteration 57, loss = 0.37435388
Iteration 58, loss = 0.37530560
Iteration 59, loss = 0.37605492
Iteration 60, loss = 0.37562354
Iteration 61, loss = 0.37293693
Iteration 62, loss = 0.37522934
Iteration 63, loss = 0.37526778
Iteration 64, loss = 0.37274800
Iteration 65, loss = 0.37411686
Iteration 66, loss = 0.37491967
Iteration 67, loss = 0.37453865
Iteration 68, loss = 0.37136994
Iteration 69, loss = 0.37308683
Iteration 70, loss = 0.37176799
Iteration 71, loss = 0.37305246
Iteration 72, loss = 0.37296631
Iteration 73, loss = 0.37506452
Iteration 74, loss = 0.37091413
Iteration 75, loss = 0.37133603
Iteration 76, loss = 0.37169803
Iteration 77, loss = 0.37168612
Iteration 78, loss = 0.37197596
Iteration 79, loss = 0.37139814
Iteration 80, loss = 0.36943963
Iteration 81, loss = 0.37044203
Iteration 82, loss = 0.37110907
Iteration 83, loss = 0.36958947
Iteration 84, loss = 0.37136986
Iteration 85, loss = 0.37043443
Iteration 86, loss = 0.37035878
Iteration 87, loss = 0.36744583
Iteration 88, loss = 0.36961788
Iteration 89, loss = 0.36909828
Iteration 90, loss = 0.36938473
Iteration 91, loss = 0.36978823
Iteration 92, loss = 0.36808633
Iteration 93, loss = 0.36815257
Iteration 94, loss = 0.37051080
Iteration 95, loss = 0.36772302
Iteration 96, loss = 0.36828622
Iteration 97, loss = 0.36850908
Iteration 98, loss = 0.36957915
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
training finished.
training accuracy: 0.827653997378768
number of correct predictions: 9247
validation accuracy: 0.7614459815546772
validation precision: 0.4834099030117407
validation recall: 0.3343926553672316
validation mcc: 0.25949685697728997
validation f1: 0.39532456689626383
validation confusion matrix: [[8300 1012]
 [1885  947]]
----------------------------------------------
2th fold cross-validation
integrating files of  ../control_vs_heme_ft_cv/cv2/train/control/
number of files: 84096
size of feature vector: 2048
size of feature matrix: (84096, 2048)
size of label vector: (84096,)
size of training data of control class:(84096, 2048)
number of training data points of control:84096
integrating files of  ../control_vs_heme_ft_cv/cv2/train/heme/
number of files: 25776
size of feature vector: 2048
size of feature matrix: (25776, 2048)
size of label vector: (25776,)
size of training data of heme class:(25776, 2048)
number of training data points of heme:25776
integrating files of  ../control_vs_heme_ft_cv/cv2/val/control/
number of files: 9312
size of feature vector: 2048
size of feature matrix: (9312, 2048)
size of label vector: (9312,)
size of val data of control class:(9312, 2048)
number of val data points of control:9312
integrating files of  ../control_vs_heme_ft_cv/cv2/val/heme/
number of files: 2832
size of feature vector: 2048
size of feature matrix: (2832, 2048)
size of label vector: (2832,)
size of val data of heme class:(2832, 2048)
number of val data points of heme:2832
shape of X_train: (109872, 2048)
shape of y_train: (109872,)
shape of X_val: (12144, 2048)
shape of y_val: (12144,)
training the MLP...
Iteration 1, loss = 0.48053319
Iteration 2, loss = 0.44959924
Iteration 3, loss = 0.44728960
Iteration 4, loss = 0.44353734
Iteration 5, loss = 0.44192343
Iteration 6, loss = 0.44140572
Iteration 7, loss = 0.43762217
Iteration 8, loss = 0.43506462
Iteration 9, loss = 0.43216057
Iteration 10, loss = 0.42911995
Iteration 11, loss = 0.42898415
Iteration 12, loss = 0.42658312
Iteration 13, loss = 0.42499518
Iteration 14, loss = 0.42277928
Iteration 15, loss = 0.42284065
Iteration 16, loss = 0.41916878
Iteration 17, loss = 0.41820161
Iteration 18, loss = 0.41774156
Iteration 19, loss = 0.41695020
Iteration 20, loss = 0.41585206
Iteration 21, loss = 0.41424120
Iteration 22, loss = 0.41475329
Iteration 23, loss = 0.41334347
Iteration 24, loss = 0.41300896
Iteration 25, loss = 0.41319132
Iteration 26, loss = 0.41141174
Iteration 27, loss = 0.41206232
Iteration 28, loss = 0.41048042
Iteration 29, loss = 0.41065075
Iteration 30, loss = 0.41066075
Iteration 31, loss = 0.40977242
Iteration 32, loss = 0.40930463
Iteration 33, loss = 0.40883724
Iteration 34, loss = 0.40990151
Iteration 35, loss = 0.40745989
Iteration 36, loss = 0.40655019
Iteration 37, loss = 0.40770322
Iteration 38, loss = 0.40706314
Iteration 39, loss = 0.40628400
Iteration 40, loss = 0.40778025
Iteration 41, loss = 0.40593046
Iteration 42, loss = 0.40531849
Iteration 43, loss = 0.40698142
Iteration 44, loss = 0.40503557
Iteration 45, loss = 0.40452414
Iteration 46, loss = 0.40497980
Iteration 47, loss = 0.40496111
Iteration 48, loss = 0.40300080
Iteration 49, loss = 0.40460271
Iteration 50, loss = 0.40372355
Iteration 51, loss = 0.40360740
Iteration 52, loss = 0.40257377
Iteration 53, loss = 0.40398214
Iteration 54, loss = 0.40194466
Iteration 55, loss = 0.40270170
Iteration 56, loss = 0.40311436
Iteration 57, loss = 0.40213854
Iteration 58, loss = 0.40046424
Iteration 59, loss = 0.40094102
Iteration 60, loss = 0.40198648
Iteration 61, loss = 0.40137432
Iteration 62, loss = 0.40028355
Iteration 63, loss = 0.39919174
Iteration 64, loss = 0.39990849
Iteration 65, loss = 0.40099368
Iteration 66, loss = 0.39916063
Iteration 67, loss = 0.39888447
Iteration 68, loss = 0.39770625
Iteration 69, loss = 0.39880003
Iteration 70, loss = 0.39759172
Iteration 71, loss = 0.39711956
Iteration 72, loss = 0.39737680
Iteration 73, loss = 0.39929441
Iteration 74, loss = 0.39733109
Iteration 75, loss = 0.39837743
Iteration 76, loss = 0.39711908
Iteration 77, loss = 0.39658247
Iteration 78, loss = 0.39714770
Iteration 79, loss = 0.39648185
Iteration 80, loss = 0.39482695
Iteration 81, loss = 0.39625367
Iteration 82, loss = 0.39775790
Iteration 83, loss = 0.39681281
Iteration 84, loss = 0.39622637
Iteration 85, loss = 0.39518394
Iteration 86, loss = 0.39630346
Iteration 87, loss = 0.39572467
Iteration 88, loss = 0.39260367
Iteration 89, loss = 0.39748988
Iteration 90, loss = 0.39577522
Iteration 91, loss = 0.39377069
Iteration 92, loss = 0.39346322
Iteration 93, loss = 0.39498725
Iteration 94, loss = 0.39681447
Iteration 95, loss = 0.39560447
Iteration 96, loss = 0.39522248
Iteration 97, loss = 0.39384718
Iteration 98, loss = 0.39342556
Iteration 99, loss = 0.39302268
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
training finished.
training accuracy: 0.8269076743847386
number of correct predictions: 9405
validation accuracy: 0.7744565217391305
validation precision: 0.5174092100336952
validation recall: 0.4879943502824859
validation mcc: 0.35688028519580955
validation f1: 0.5022714882791205
validation confusion matrix: [[8023 1289]
 [1450 1382]]
----------------------------------------------
3th fold cross-validation
integrating files of  ../control_vs_heme_ft_cv/cv3/train/control/
number of files: 84096
size of feature vector: 2048
size of feature matrix: (84096, 2048)
size of label vector: (84096,)
size of training data of control class:(84096, 2048)
number of training data points of control:84096
integrating files of  ../control_vs_heme_ft_cv/cv3/train/heme/
number of files: 25776
size of feature vector: 2048
size of feature matrix: (25776, 2048)
size of label vector: (25776,)
size of training data of heme class:(25776, 2048)
number of training data points of heme:25776
integrating files of  ../control_vs_heme_ft_cv/cv3/val/control/
number of files: 9312
size of feature vector: 2048
size of feature matrix: (9312, 2048)
size of label vector: (9312,)
size of val data of control class:(9312, 2048)
number of val data points of control:9312
integrating files of  ../control_vs_heme_ft_cv/cv3/val/heme/
number of files: 2832
size of feature vector: 2048
size of feature matrix: (2832, 2048)
size of label vector: (2832,)
size of val data of heme class:(2832, 2048)
number of val data points of heme:2832
shape of X_train: (109872, 2048)
shape of y_train: (109872,)
shape of X_val: (12144, 2048)
shape of y_val: (12144,)
training the MLP...
Iteration 1, loss = 0.48141145
Iteration 2, loss = 0.44801952
Iteration 3, loss = 0.44343412
Iteration 4, loss = 0.44065152
Iteration 5, loss = 0.43769039
Iteration 6, loss = 0.43398009
Iteration 7, loss = 0.43255595
Iteration 8, loss = 0.42950650
Iteration 9, loss = 0.42759094
Iteration 10, loss = 0.42524672
Iteration 11, loss = 0.42441657
Iteration 12, loss = 0.42117046
Iteration 13, loss = 0.41988573
Iteration 14, loss = 0.41783998
Iteration 15, loss = 0.41730138
Iteration 16, loss = 0.41643253
Iteration 17, loss = 0.41411497
Iteration 18, loss = 0.41346788
Iteration 19, loss = 0.41293225
Iteration 20, loss = 0.41299184
Iteration 21, loss = 0.41127936
Iteration 22, loss = 0.41162256
Iteration 23, loss = 0.41061022
Iteration 24, loss = 0.40890907
Iteration 25, loss = 0.40914225
Iteration 26, loss = 0.40983452
Iteration 27, loss = 0.40814954
Iteration 28, loss = 0.40798773
Iteration 29, loss = 0.40740290
Iteration 30, loss = 0.40730884
Iteration 31, loss = 0.40620828
Iteration 32, loss = 0.40637860
Iteration 33, loss = 0.40537095
Iteration 34, loss = 0.40526849
Iteration 35, loss = 0.40616507
Iteration 36, loss = 0.40463111
Iteration 37, loss = 0.40454523
Iteration 38, loss = 0.40489644
Iteration 39, loss = 0.40427413
Iteration 40, loss = 0.40308460
Iteration 41, loss = 0.40283181
Iteration 42, loss = 0.40248510
Iteration 43, loss = 0.40390902
Iteration 44, loss = 0.40233027
Iteration 45, loss = 0.40165731
Iteration 46, loss = 0.40182554
Iteration 47, loss = 0.40156983
Iteration 48, loss = 0.40106076
Iteration 49, loss = 0.40271886
Iteration 50, loss = 0.40012539
Iteration 51, loss = 0.40110137
Iteration 52, loss = 0.40159619
Iteration 53, loss = 0.40108894
Iteration 54, loss = 0.39917380
Iteration 55, loss = 0.39992194
Iteration 56, loss = 0.39927391
Iteration 57, loss = 0.40184694
Iteration 58, loss = 0.40062902
Iteration 59, loss = 0.39861578
Iteration 60, loss = 0.39836627
Iteration 61, loss = 0.39875689
Iteration 62, loss = 0.39761787
Iteration 63, loss = 0.39856667
Iteration 64, loss = 0.39698056
Iteration 65, loss = 0.39726830
Iteration 66, loss = 0.39807519
Iteration 67, loss = 0.39907893
Iteration 68, loss = 0.39744595
Iteration 69, loss = 0.39704297
Iteration 70, loss = 0.39650834
Iteration 71, loss = 0.39782102
Iteration 72, loss = 0.39869702
Iteration 73, loss = 0.39641700
Iteration 74, loss = 0.39645056
Iteration 75, loss = 0.39696306
Iteration 76, loss = 0.39570771
Iteration 77, loss = 0.39433372
Iteration 78, loss = 0.39709289
Iteration 79, loss = 0.39627162
Iteration 80, loss = 0.39559187
Iteration 81, loss = 0.39715600
Iteration 82, loss = 0.39644144
Iteration 83, loss = 0.39530866
Iteration 84, loss = 0.39566677
Iteration 85, loss = 0.39704124
Iteration 86, loss = 0.39377482
Iteration 87, loss = 0.39382427
Iteration 88, loss = 0.39492944
Iteration 89, loss = 0.39351052
Iteration 90, loss = 0.39433371
Iteration 91, loss = 0.39581902
Iteration 92, loss = 0.39588287
Iteration 93, loss = 0.39527101
Iteration 94, loss = 0.39525924
Iteration 95, loss = 0.39543912
Iteration 96, loss = 0.39601540
Iteration 97, loss = 0.39436785
Iteration 98, loss = 0.39507154
Iteration 99, loss = 0.39492242
Iteration 100, loss = 0.39452325
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
training finished.
training accuracy: 0.8263615843891073
number of correct predictions: 9093
validation accuracy: 0.7487648221343873
validation precision: 0.46491509131688563
validation recall: 0.5123587570621468
validation mcc: 0.3222674276563614
validation f1: 0.48748530152864106
validation confusion matrix: [[7642 1670]
 [1381 1451]]
----------------------------------------------
4th fold cross-validation
integrating files of  ../control_vs_heme_ft_cv/cv4/train/control/
number of files: 84096
size of feature vector: 2048
size of feature matrix: (84096, 2048)
size of label vector: (84096,)
size of training data of control class:(84096, 2048)
number of training data points of control:84096
integrating files of  ../control_vs_heme_ft_cv/cv4/train/heme/
number of files: 25776
size of feature vector: 2048
size of feature matrix: (25776, 2048)
size of label vector: (25776,)
size of training data of heme class:(25776, 2048)
number of training data points of heme:25776
integrating files of  ../control_vs_heme_ft_cv/cv4/val/control/
number of files: 9312
size of feature vector: 2048
size of feature matrix: (9312, 2048)
size of label vector: (9312,)
size of val data of control class:(9312, 2048)
number of val data points of control:9312
integrating files of  ../control_vs_heme_ft_cv/cv4/val/heme/
number of files: 2832
size of feature vector: 2048
size of feature matrix: (2832, 2048)
size of label vector: (2832,)
size of val data of heme class:(2832, 2048)
number of val data points of heme:2832
shape of X_train: (109872, 2048)
shape of y_train: (109872,)
shape of X_val: (12144, 2048)
shape of y_val: (12144,)
training the MLP...
Iteration 1, loss = 0.47631515
Iteration 2, loss = 0.44638898
Iteration 3, loss = 0.44274471
Iteration 4, loss = 0.44155968
Iteration 5, loss = 0.43860542
Iteration 6, loss = 0.43462491
Iteration 7, loss = 0.43078889
Iteration 8, loss = 0.42836990
Iteration 9, loss = 0.42304685
Iteration 10, loss = 0.41941445
Iteration 11, loss = 0.41597968
Iteration 12, loss = 0.41205270
Iteration 13, loss = 0.40904384
Iteration 14, loss = 0.40616782
Iteration 15, loss = 0.40313456
Iteration 16, loss = 0.40069648
Iteration 17, loss = 0.39967893
Iteration 18, loss = 0.39873164
Iteration 19, loss = 0.39907985
Iteration 20, loss = 0.39409453
Iteration 21, loss = 0.39287669
Iteration 22, loss = 0.39105301
Iteration 23, loss = 0.39025721
Iteration 24, loss = 0.38895225
Iteration 25, loss = 0.38875688
Iteration 26, loss = 0.38728620
Iteration 27, loss = 0.38642029
Iteration 28, loss = 0.38471938
Iteration 29, loss = 0.38364740
Iteration 30, loss = 0.38332252
Iteration 31, loss = 0.38255964
Iteration 32, loss = 0.38061791
Iteration 33, loss = 0.37964478
Iteration 34, loss = 0.38044999
Iteration 35, loss = 0.37909645
Iteration 36, loss = 0.37799816
Iteration 37, loss = 0.37736486
Iteration 38, loss = 0.37777464
Iteration 39, loss = 0.37626301
Iteration 40, loss = 0.37548786
Iteration 41, loss = 0.37526058
Iteration 42, loss = 0.37517003
Iteration 43, loss = 0.37295282
Iteration 44, loss = 0.37364854
Iteration 45, loss = 0.37438845
Iteration 46, loss = 0.37135524
Iteration 47, loss = 0.37133106
Iteration 48, loss = 0.37038620
Iteration 49, loss = 0.37093309
Iteration 50, loss = 0.36980928
Iteration 51, loss = 0.36972735
Iteration 52, loss = 0.36821153
Iteration 53, loss = 0.36944261
Iteration 54, loss = 0.36736495
Iteration 55, loss = 0.36835369
Iteration 56, loss = 0.36614466
Iteration 57, loss = 0.36658099
Iteration 58, loss = 0.36514123
Iteration 59, loss = 0.36603970
Iteration 60, loss = 0.36599482
Iteration 61, loss = 0.36265617
Iteration 62, loss = 0.36656998
Iteration 63, loss = 0.36403905
Iteration 64, loss = 0.36469091
Iteration 65, loss = 0.36365676
Iteration 66, loss = 0.36618358
Iteration 67, loss = 0.36263037
Iteration 68, loss = 0.36288496
Iteration 69, loss = 0.36563856
Iteration 70, loss = 0.36207714
Iteration 71, loss = 0.36419845
Iteration 72, loss = 0.36229039
Iteration 73, loss = 0.36200519
Iteration 74, loss = 0.36167236
Iteration 75, loss = 0.36160477
Iteration 76, loss = 0.36092649
Iteration 77, loss = 0.35908543
Iteration 78, loss = 0.35948085
Iteration 79, loss = 0.36096691
Iteration 80, loss = 0.35953009
Iteration 81, loss = 0.35677825
Iteration 82, loss = 0.35894613
Iteration 83, loss = 0.35903956
Iteration 84, loss = 0.35936652
Iteration 85, loss = 0.36066178
Iteration 86, loss = 0.35843614
Iteration 87, loss = 0.35782896
Iteration 88, loss = 0.35803490
Iteration 89, loss = 0.35787177
Iteration 90, loss = 0.35809663
Iteration 91, loss = 0.35752939
Iteration 92, loss = 0.35760149
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
training finished.
training accuracy: 0.8675731760594146
number of correct predictions: 9100
validation accuracy: 0.7493412384716732
validation precision: 0.4636986301369863
validation recall: 0.4781073446327684
validation mcc: 0.3066837738540263
validation f1: 0.47079276773296247
validation confusion matrix: [[7746 1566]
 [1478 1354]]
----------------------------------------------
5th fold cross-validation
integrating files of  ../control_vs_heme_ft_cv/cv5/train/control/
number of files: 84096
size of feature vector: 2048
size of feature matrix: (84096, 2048)
size of label vector: (84096,)
size of training data of control class:(84096, 2048)
number of training data points of control:84096
integrating files of  ../control_vs_heme_ft_cv/cv5/train/heme/
number of files: 25776
size of feature vector: 2048
size of feature matrix: (25776, 2048)
size of label vector: (25776,)
size of training data of heme class:(25776, 2048)
number of training data points of heme:25776
integrating files of  ../control_vs_heme_ft_cv/cv5/val/control/
number of files: 9312
size of feature vector: 2048
size of feature matrix: (9312, 2048)
size of label vector: (9312,)
size of val data of control class:(9312, 2048)
number of val data points of control:9312
integrating files of  ../control_vs_heme_ft_cv/cv5/val/heme/
number of files: 2832
size of feature vector: 2048
size of feature matrix: (2832, 2048)
size of label vector: (2832,)
size of val data of heme class:(2832, 2048)
number of val data points of heme:2832
shape of X_train: (109872, 2048)
shape of y_train: (109872,)
shape of X_val: (12144, 2048)
shape of y_val: (12144,)
training the MLP...
Iteration 1, loss = 0.48490049
Iteration 2, loss = 0.45134778
Iteration 3, loss = 0.44994732
Iteration 4, loss = 0.44539238
Iteration 5, loss = 0.44426024
Iteration 6, loss = 0.44258917
Iteration 7, loss = 0.44175413
Iteration 8, loss = 0.44080649
Iteration 9, loss = 0.43837713
Iteration 10, loss = 0.43691044
Iteration 11, loss = 0.43553015
Iteration 12, loss = 0.43481727
Iteration 13, loss = 0.43328437
Iteration 14, loss = 0.43189339
Iteration 15, loss = 0.43142023
Iteration 16, loss = 0.42975400
Iteration 17, loss = 0.42978719
Iteration 18, loss = 0.42840236
Iteration 19, loss = 0.42709352
Iteration 20, loss = 0.42770057
Iteration 21, loss = 0.42523199
Iteration 22, loss = 0.42576992
Iteration 23, loss = 0.42410380
Iteration 24, loss = 0.42419108
Iteration 25, loss = 0.42409003
Iteration 26, loss = 0.42210996
Iteration 27, loss = 0.42308369
Iteration 28, loss = 0.42269840
Iteration 29, loss = 0.42215311
Iteration 30, loss = 0.42125400
Iteration 31, loss = 0.42043140
Iteration 32, loss = 0.42118106
Iteration 33, loss = 0.42102801
Iteration 34, loss = 0.41997908
Iteration 35, loss = 0.41962430
Iteration 36, loss = 0.41919977
Iteration 37, loss = 0.41858439
Iteration 38, loss = 0.41889289
Iteration 39, loss = 0.41871118
Iteration 40, loss = 0.41806130
Iteration 41, loss = 0.41877866
Iteration 42, loss = 0.41752864
Iteration 43, loss = 0.41698017
Iteration 44, loss = 0.41787425
Iteration 45, loss = 0.41750160
Iteration 46, loss = 0.41670111
Iteration 47, loss = 0.41650015
Iteration 48, loss = 0.41667220
Iteration 49, loss = 0.41763850
Iteration 50, loss = 0.41518868
Iteration 51, loss = 0.41514838
Iteration 52, loss = 0.41513612
Iteration 53, loss = 0.41533640
Iteration 54, loss = 0.41443895
Iteration 55, loss = 0.41466903
Iteration 56, loss = 0.41513918
Iteration 57, loss = 0.41430652
Iteration 58, loss = 0.41291464
Iteration 59, loss = 0.41380547
Iteration 60, loss = 0.41395931
Iteration 61, loss = 0.41265739
Iteration 62, loss = 0.41234770
Iteration 63, loss = 0.41351755
Iteration 64, loss = 0.41176082
Iteration 65, loss = 0.41163005
Iteration 66, loss = 0.41222226
Iteration 67, loss = 0.41217953
Iteration 68, loss = 0.41145831
Iteration 69, loss = 0.41257762
Iteration 70, loss = 0.41218084
Iteration 71, loss = 0.41102276
Iteration 72, loss = 0.41230399
Iteration 73, loss = 0.41053594
Iteration 74, loss = 0.41107420
Iteration 75, loss = 0.41112880
Iteration 76, loss = 0.41048021
Iteration 77, loss = 0.41071437
Iteration 78, loss = 0.40951021
Iteration 79, loss = 0.41059729
Iteration 80, loss = 0.41065522
Iteration 81, loss = 0.40893701
Iteration 82, loss = 0.41071640
Iteration 83, loss = 0.40973412
Iteration 84, loss = 0.40929920
Iteration 85, loss = 0.41027683
Iteration 86, loss = 0.40850995
Iteration 87, loss = 0.40955230
Iteration 88, loss = 0.40962816
Iteration 89, loss = 0.40910472
Iteration 90, loss = 0.40879632
Iteration 91, loss = 0.40859050
Iteration 92, loss = 0.40931282
Iteration 93, loss = 0.40923085
Iteration 94, loss = 0.40872104
Iteration 95, loss = 0.41048387
Iteration 96, loss = 0.40983314
Iteration 97, loss = 0.40896899
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
training finished.
training accuracy: 0.817341997961264
number of correct predictions: 9250
validation accuracy: 0.7616930171277997
validation precision: 0.49097262667443214
validation recall: 0.5953389830508474
validation mcc: 0.3827532187375114
validation f1: 0.5381423555697414
validation confusion matrix: [[7564 1748]
 [1146 1686]]
----------------------------------------------
6th fold cross-validation
integrating files of  ../control_vs_heme_ft_cv/cv6/train/control/
number of files: 84096
size of feature vector: 2048
size of feature matrix: (84096, 2048)
size of label vector: (84096,)
size of training data of control class:(84096, 2048)
number of training data points of control:84096
integrating files of  ../control_vs_heme_ft_cv/cv6/train/heme/
number of files: 25776
size of feature vector: 2048
size of feature matrix: (25776, 2048)
size of label vector: (25776,)
size of training data of heme class:(25776, 2048)
number of training data points of heme:25776
integrating files of  ../control_vs_heme_ft_cv/cv6/val/control/
number of files: 9312
size of feature vector: 2048
size of feature matrix: (9312, 2048)
size of label vector: (9312,)
size of val data of control class:(9312, 2048)
number of val data points of control:9312
integrating files of  ../control_vs_heme_ft_cv/cv6/val/heme/
number of files: 2832
size of feature vector: 2048
size of feature matrix: (2832, 2048)
size of label vector: (2832,)
size of val data of heme class:(2832, 2048)
number of val data points of heme:2832
shape of X_train: (109872, 2048)
shape of y_train: (109872,)
shape of X_val: (12144, 2048)
shape of y_val: (12144,)
training the MLP...
Iteration 1, loss = 0.47858840
Iteration 2, loss = 0.44693428
Iteration 3, loss = 0.44420932
Iteration 4, loss = 0.44300974
Iteration 5, loss = 0.44230808
Iteration 6, loss = 0.44001832
Iteration 7, loss = 0.44004134
Iteration 8, loss = 0.43838075
Iteration 9, loss = 0.43899032
Iteration 10, loss = 0.43887879
Iteration 11, loss = 0.43833267
Iteration 12, loss = 0.43818378
Iteration 13, loss = 0.43757765
Iteration 14, loss = 0.43778941
Iteration 15, loss = 0.43827039
Iteration 16, loss = 0.43739268
Iteration 17, loss = 0.43698885
Iteration 18, loss = 0.43702195
Iteration 19, loss = 0.43610666
Iteration 20, loss = 0.43646482
Iteration 21, loss = 0.43628892
Iteration 22, loss = 0.43611773
Iteration 23, loss = 0.43585381
Iteration 24, loss = 0.43597619
Iteration 25, loss = 0.43590186
Iteration 26, loss = 0.43632815
Iteration 27, loss = 0.43603189
Iteration 28, loss = 0.43604612
Iteration 29, loss = 0.43545446
Iteration 30, loss = 0.43582474
Iteration 31, loss = 0.43565751
Iteration 32, loss = 0.43513364
Iteration 33, loss = 0.43594096
Iteration 34, loss = 0.43544740
Iteration 35, loss = 0.43573265
Iteration 36, loss = 0.43560558
Iteration 37, loss = 0.43568119
Iteration 38, loss = 0.43461448
Iteration 39, loss = 0.43515677
Iteration 40, loss = 0.43555192
Iteration 41, loss = 0.43502898
Iteration 42, loss = 0.43508476
Iteration 43, loss = 0.43478228
Iteration 44, loss = 0.43460226
Iteration 45, loss = 0.43538896
Iteration 46, loss = 0.43412643
Iteration 47, loss = 0.43560000
Iteration 48, loss = 0.43454123
Iteration 49, loss = 0.43413178
Iteration 50, loss = 0.43538711
Iteration 51, loss = 0.43397020
Iteration 52, loss = 0.43478347
Iteration 53, loss = 0.43438177
Iteration 54, loss = 0.43453978
Iteration 55, loss = 0.43433433
Iteration 56, loss = 0.43466117
Iteration 57, loss = 0.43454982
Iteration 58, loss = 0.43442527
Iteration 59, loss = 0.43428097
Iteration 60, loss = 0.43430352
Iteration 61, loss = 0.43441731
Iteration 62, loss = 0.43385189
Iteration 63, loss = 0.43372869
Iteration 64, loss = 0.43395202
Iteration 65, loss = 0.43329690
Iteration 66, loss = 0.43395964
Iteration 67, loss = 0.43387766
Iteration 68, loss = 0.43292714
Iteration 69, loss = 0.43361490
Iteration 70, loss = 0.43405263
Iteration 71, loss = 0.43376939
Iteration 72, loss = 0.43369739
Iteration 73, loss = 0.43404052
Iteration 74, loss = 0.43344124
Iteration 75, loss = 0.43317787
Iteration 76, loss = 0.43375925
Iteration 77, loss = 0.43315368
Iteration 78, loss = 0.43410333
Iteration 79, loss = 0.43298044
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
training finished.
training accuracy: 0.789218363186253
number of correct predictions: 9380
validation accuracy: 0.7723978919631094
validation precision: 0.510759493670886
validation recall: 0.5699152542372882
validation mcc: 0.38927447962512807
validation f1: 0.5387182910547396
validation confusion matrix: [[7766 1546]
 [1218 1614]]
----------------------------------------------
7th fold cross-validation
integrating files of  ../control_vs_heme_ft_cv/cv7/train/control/
number of files: 84096
size of feature vector: 2048
size of feature matrix: (84096, 2048)
size of label vector: (84096,)
size of training data of control class:(84096, 2048)
number of training data points of control:84096
integrating files of  ../control_vs_heme_ft_cv/cv7/train/heme/
number of files: 25776
size of feature vector: 2048
size of feature matrix: (25776, 2048)
size of label vector: (25776,)
size of training data of heme class:(25776, 2048)
number of training data points of heme:25776
integrating files of  ../control_vs_heme_ft_cv/cv7/val/control/
number of files: 9312
size of feature vector: 2048
size of feature matrix: (9312, 2048)
size of label vector: (9312,)
size of val data of control class:(9312, 2048)
number of val data points of control:9312
integrating files of  ../control_vs_heme_ft_cv/cv7/val/heme/
number of files: 2832
size of feature vector: 2048
size of feature matrix: (2832, 2048)
size of label vector: (2832,)
size of val data of heme class:(2832, 2048)
number of val data points of heme:2832
shape of X_train: (109872, 2048)
shape of y_train: (109872,)
shape of X_val: (12144, 2048)
shape of y_val: (12144,)
training the MLP...
Iteration 1, loss = 0.47713029
Iteration 2, loss = 0.44721355
Iteration 3, loss = 0.44210941
Iteration 4, loss = 0.44024099
Iteration 5, loss = 0.43894411
Iteration 6, loss = 0.43783335
Iteration 7, loss = 0.43733955
Iteration 8, loss = 0.43576252
Iteration 9, loss = 0.43629983
Iteration 10, loss = 0.43638712
Iteration 11, loss = 0.43570225
Iteration 12, loss = 0.43553478
Iteration 13, loss = 0.43478021
Iteration 14, loss = 0.43537337
Iteration 15, loss = 0.43390208
Iteration 16, loss = 0.43389875
Iteration 17, loss = 0.43434317
Iteration 18, loss = 0.43300997
Iteration 19, loss = 0.43321743
Iteration 20, loss = 0.43337872
Iteration 21, loss = 0.43305281
Iteration 22, loss = 0.43380149
Iteration 23, loss = 0.43382292
Iteration 24, loss = 0.43290211
Iteration 25, loss = 0.43267435
Iteration 26, loss = 0.43301725
Iteration 27, loss = 0.43239611
Iteration 28, loss = 0.43291007
Iteration 29, loss = 0.43280469
Iteration 30, loss = 0.43273914
Iteration 31, loss = 0.43227437
Iteration 32, loss = 0.43208777
Iteration 33, loss = 0.43226373
Iteration 34, loss = 0.43181701
Iteration 35, loss = 0.43140641
Iteration 36, loss = 0.43281837
Iteration 37, loss = 0.43198461
Iteration 38, loss = 0.43255402
Iteration 39, loss = 0.43176780
Iteration 40, loss = 0.43168321
Iteration 41, loss = 0.43154956
Iteration 42, loss = 0.43163780
Iteration 43, loss = 0.43162997
Iteration 44, loss = 0.43169672
Iteration 45, loss = 0.43130718
Iteration 46, loss = 0.43185526
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
training finished.
training accuracy: 0.7932776321537789
number of correct predictions: 9048
validation accuracy: 0.7450592885375494
validation precision: 0.45217391304347826
validation recall: 0.4406779661016949
validation mcc: 0.2808299582653037
validation f1: 0.4463519313304721
validation confusion matrix: [[7800 1512]
 [1584 1248]]
----------------------------------------------
8th fold cross-validation
integrating files of  ../control_vs_heme_ft_cv/cv8/train/control/
number of files: 84096
size of feature vector: 2048
size of feature matrix: (84096, 2048)
size of label vector: (84096,)
size of training data of control class:(84096, 2048)
number of training data points of control:84096
integrating files of  ../control_vs_heme_ft_cv/cv8/train/heme/
number of files: 25776
size of feature vector: 2048
size of feature matrix: (25776, 2048)
size of label vector: (25776,)
size of training data of heme class:(25776, 2048)
number of training data points of heme:25776
integrating files of  ../control_vs_heme_ft_cv/cv8/val/control/
number of files: 9312
size of feature vector: 2048
size of feature matrix: (9312, 2048)
size of label vector: (9312,)
size of val data of control class:(9312, 2048)
number of val data points of control:9312
integrating files of  ../control_vs_heme_ft_cv/cv8/val/heme/
number of files: 2832
size of feature vector: 2048
size of feature matrix: (2832, 2048)
size of label vector: (2832,)
size of val data of heme class:(2832, 2048)
number of val data points of heme:2832
shape of X_train: (109872, 2048)
shape of y_train: (109872,)
shape of X_val: (12144, 2048)
shape of y_val: (12144,)
training the MLP...
Iteration 1, loss = 0.47660278
Iteration 2, loss = 0.44598705
Iteration 3, loss = 0.43521989
Iteration 4, loss = 0.43090957
Iteration 5, loss = 0.42823722
Iteration 6, loss = 0.42511511
Iteration 7, loss = 0.42150472
Iteration 8, loss = 0.42101476
Iteration 9, loss = 0.41787137
Iteration 10, loss = 0.41570017
Iteration 11, loss = 0.41444778
Iteration 12, loss = 0.41548497
Iteration 13, loss = 0.41105853
Iteration 14, loss = 0.40982702
Iteration 15, loss = 0.40838063
Iteration 16, loss = 0.40713099
Iteration 17, loss = 0.40869252
Iteration 18, loss = 0.40567253
Iteration 19, loss = 0.40557004
Iteration 20, loss = 0.40356169
Iteration 21, loss = 0.40363290
Iteration 22, loss = 0.40260941
Iteration 23, loss = 0.40181472
Iteration 24, loss = 0.40357297
Iteration 25, loss = 0.40086341
Iteration 26, loss = 0.40019672
Iteration 27, loss = 0.40090179
Iteration 28, loss = 0.40010246
Iteration 29, loss = 0.39941017
Iteration 30, loss = 0.39957256
Iteration 31, loss = 0.39691018
Iteration 32, loss = 0.39755746
Iteration 33, loss = 0.39782318
Iteration 34, loss = 0.39684324
Iteration 35, loss = 0.39779276
Iteration 36, loss = 0.39681028
Iteration 37, loss = 0.39714802
Iteration 38, loss = 0.39658899
Iteration 39, loss = 0.39532466
Iteration 40, loss = 0.39517510
Iteration 41, loss = 0.39279711
Iteration 42, loss = 0.39499900
Iteration 43, loss = 0.39340728
Iteration 44, loss = 0.39320179
Iteration 45, loss = 0.39354191
Iteration 46, loss = 0.39330639
Iteration 47, loss = 0.39365321
Iteration 48, loss = 0.39164215
Iteration 49, loss = 0.39206246
Iteration 50, loss = 0.39160765
Iteration 51, loss = 0.39841928
Iteration 52, loss = 0.39199870
Iteration 53, loss = 0.39142352
Iteration 54, loss = 0.39010642
Iteration 55, loss = 0.38945011
Iteration 56, loss = 0.38875935
Iteration 57, loss = 0.38990742
Iteration 58, loss = 0.38850394
Iteration 59, loss = 0.39159297
Iteration 60, loss = 0.38874059
Iteration 61, loss = 0.38907054
Iteration 62, loss = 0.39028008
Iteration 63, loss = 0.38793225
Iteration 64, loss = 0.38703079
Iteration 65, loss = 0.38604770
Iteration 66, loss = 0.39035510
Iteration 67, loss = 0.39042347
Iteration 68, loss = 0.38690815
Iteration 69, loss = 0.38625847
Iteration 70, loss = 0.38572351
Iteration 71, loss = 0.38645875
Iteration 72, loss = 0.38607474
Iteration 73, loss = 0.38606486
Iteration 74, loss = 0.38635343
Iteration 75, loss = 0.38725079
Iteration 76, loss = 0.39703529
Iteration 77, loss = 0.38983932
Iteration 78, loss = 0.39560008
Iteration 79, loss = 0.39587645
Iteration 80, loss = 0.39488913
Iteration 81, loss = 0.39571877
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
training finished.
training accuracy: 0.8131189019950488
number of correct predictions: 9306
validation accuracy: 0.7663043478260869
validation precision: 0.499009900990099
validation recall: 0.5338983050847458
validation mcc: 0.3624340758243488
validation f1: 0.5158648925281475
validation confusion matrix: [[7794 1518]
 [1320 1512]]
----------------------------------------------
9th fold cross-validation
integrating files of  ../control_vs_heme_ft_cv/cv9/train/control/
number of files: 84096
size of feature vector: 2048
size of feature matrix: (84096, 2048)
size of label vector: (84096,)
size of training data of control class:(84096, 2048)
number of training data points of control:84096
integrating files of  ../control_vs_heme_ft_cv/cv9/train/heme/
number of files: 25776
size of feature vector: 2048
size of feature matrix: (25776, 2048)
size of label vector: (25776,)
size of training data of heme class:(25776, 2048)
number of training data points of heme:25776
integrating files of  ../control_vs_heme_ft_cv/cv9/val/control/
number of files: 9312
size of feature vector: 2048
size of feature matrix: (9312, 2048)
size of label vector: (9312,)
size of val data of control class:(9312, 2048)
number of val data points of control:9312
integrating files of  ../control_vs_heme_ft_cv/cv9/val/heme/
number of files: 2832
size of feature vector: 2048
size of feature matrix: (2832, 2048)
size of label vector: (2832,)
size of val data of heme class:(2832, 2048)
number of val data points of heme:2832
shape of X_train: (109872, 2048)
shape of y_train: (109872,)
shape of X_val: (12144, 2048)
shape of y_val: (12144,)
training the MLP...
Iteration 1, loss = 0.48027278
Iteration 2, loss = 0.44602651
Iteration 3, loss = 0.44211780
Iteration 4, loss = 0.44066286
Iteration 5, loss = 0.43843557
Iteration 6, loss = 0.43715550
Iteration 7, loss = 0.43620156
Iteration 8, loss = 0.43360193
Iteration 9, loss = 0.43307770
Iteration 10, loss = 0.43225808
Iteration 11, loss = 0.43240066
Iteration 12, loss = 0.42913226
Iteration 13, loss = 0.42806729
Iteration 14, loss = 0.42745603
Iteration 15, loss = 0.42549053
Iteration 16, loss = 0.42495072
Iteration 17, loss = 0.42315970
Iteration 18, loss = 0.42514461
Iteration 19, loss = 0.42300874
Iteration 20, loss = 0.42172702
Iteration 21, loss = 0.42137414
Iteration 22, loss = 0.42106669
Iteration 23, loss = 0.41979979
Iteration 24, loss = 0.41925299
Iteration 25, loss = 0.41825773
Iteration 26, loss = 0.41879102
Iteration 27, loss = 0.41739631
Iteration 28, loss = 0.41686952
Iteration 29, loss = 0.41629780
Iteration 30, loss = 0.41593696
Iteration 31, loss = 0.41600501
Iteration 32, loss = 0.41452663
Iteration 33, loss = 0.41530965
Iteration 34, loss = 0.41579446
Iteration 35, loss = 0.41487991
Iteration 36, loss = 0.41396802
Iteration 37, loss = 0.41425579
Iteration 38, loss = 0.41449639
Iteration 39, loss = 0.41262789
Iteration 40, loss = 0.41336878
Iteration 41, loss = 0.41253903
Iteration 42, loss = 0.41302328
Iteration 43, loss = 0.41326040
Iteration 44, loss = 0.41193648
Iteration 45, loss = 0.41225018
Iteration 46, loss = 0.41209930
Iteration 47, loss = 0.41195105
Iteration 48, loss = 0.41142535
Iteration 49, loss = 0.41129989
Iteration 50, loss = 0.41205865
Iteration 51, loss = 0.41107902
Iteration 52, loss = 0.41182145
Iteration 53, loss = 0.41051864
Iteration 54, loss = 0.41062399
Iteration 55, loss = 0.41122032
Iteration 56, loss = 0.40947758
Iteration 57, loss = 0.41029539
Iteration 58, loss = 0.40968751
Iteration 59, loss = 0.40863808
Iteration 60, loss = 0.40870243
Iteration 61, loss = 0.40895487
Iteration 62, loss = 0.40850229
Iteration 63, loss = 0.40884091
Iteration 64, loss = 0.40860798
Iteration 65, loss = 0.40797779
Iteration 66, loss = 0.40840535
Iteration 67, loss = 0.40728979
Iteration 68, loss = 0.40782857
Iteration 69, loss = 0.40696573
Iteration 70, loss = 0.40806616
Iteration 71, loss = 0.40834053
Iteration 72, loss = 0.40730017
Iteration 73, loss = 0.40753627
Iteration 74, loss = 0.40774563
Iteration 75, loss = 0.40783762
Iteration 76, loss = 0.40594385
Iteration 77, loss = 0.40663238
Iteration 78, loss = 0.40726100
Iteration 79, loss = 0.40575049
Iteration 80, loss = 0.40686676
Iteration 81, loss = 0.40590192
Iteration 82, loss = 0.40626656
Iteration 83, loss = 0.40558478
Iteration 84, loss = 0.40529091
Iteration 85, loss = 0.40574452
Iteration 86, loss = 0.40616372
Iteration 87, loss = 0.40407500
Iteration 88, loss = 0.40591308
Iteration 89, loss = 0.40456098
Iteration 90, loss = 0.40592476
Iteration 91, loss = 0.40492349
Iteration 92, loss = 0.40458546
Iteration 93, loss = 0.40519099
Iteration 94, loss = 0.40501286
Iteration 95, loss = 0.40504674
Iteration 96, loss = 0.40516674
Iteration 97, loss = 0.40470974
Iteration 98, loss = 0.40537788
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
training finished.
training accuracy: 0.820391000436872
number of correct predictions: 9120
validation accuracy: 0.7509881422924901
validation precision: 0.4669193659545141
validation recall: 0.4784604519774011
validation mcc: 0.30970708027106175
validation f1: 0.4726194628531566
validation confusion matrix: [[7765 1547]
 [1477 1355]]
----------------------------------------------
10th fold cross-validation
integrating files of  ../control_vs_heme_ft_cv/cv10/train/control/
number of files: 84096
size of feature vector: 2048
size of feature matrix: (84096, 2048)
size of label vector: (84096,)
size of training data of control class:(84096, 2048)
number of training data points of control:84096
integrating files of  ../control_vs_heme_ft_cv/cv10/train/heme/
number of files: 25776
size of feature vector: 2048
size of feature matrix: (25776, 2048)
size of label vector: (25776,)
size of training data of heme class:(25776, 2048)
number of training data points of heme:25776
integrating files of  ../control_vs_heme_ft_cv/cv10/val/control/
number of files: 9312
size of feature vector: 2048
size of feature matrix: (9312, 2048)
size of label vector: (9312,)
size of val data of control class:(9312, 2048)
number of val data points of control:9312
integrating files of  ../control_vs_heme_ft_cv/cv10/val/heme/
number of files: 2832
size of feature vector: 2048
size of feature matrix: (2832, 2048)
size of label vector: (2832,)
size of val data of heme class:(2832, 2048)
number of val data points of heme:2832
shape of X_train: (109872, 2048)
shape of y_train: (109872,)
shape of X_val: (12144, 2048)
shape of y_val: (12144,)
training the MLP...
Iteration 1, loss = 0.47616705
Iteration 2, loss = 0.44224055
Iteration 3, loss = 0.44037541
Iteration 4, loss = 0.43717698
Iteration 5, loss = 0.43683859
Iteration 6, loss = 0.43571419
Iteration 7, loss = 0.43499356
Iteration 8, loss = 0.43536068
Iteration 9, loss = 0.43346301
Iteration 10, loss = 0.43308754
Iteration 11, loss = 0.43333822
Iteration 12, loss = 0.43262374
Iteration 13, loss = 0.43271788
Iteration 14, loss = 0.43267935
Iteration 15, loss = 0.43279278
Iteration 16, loss = 0.43190592
Iteration 17, loss = 0.43194098
Iteration 18, loss = 0.43213715
Iteration 19, loss = 0.43181795
Iteration 20, loss = 0.43119267
Iteration 21, loss = 0.43128873
Iteration 22, loss = 0.43157599
Iteration 23, loss = 0.43053294
Iteration 24, loss = 0.43112001
Iteration 25, loss = 0.43152881
Iteration 26, loss = 0.43084222
Iteration 27, loss = 0.43078215
Iteration 28, loss = 0.43055908
Iteration 29, loss = 0.42981836
Iteration 30, loss = 0.43035144
Iteration 31, loss = 0.43062732
Iteration 32, loss = 0.43086804
Iteration 33, loss = 0.43052888
Iteration 34, loss = 0.43084342
Iteration 35, loss = 0.43011810
Iteration 36, loss = 0.43018433
Iteration 37, loss = 0.42945952
Iteration 38, loss = 0.42991722
Iteration 39, loss = 0.42946104
Iteration 40, loss = 0.42976127
Iteration 41, loss = 0.42944960
Iteration 42, loss = 0.43003200
Iteration 43, loss = 0.42930700
Iteration 44, loss = 0.42932856
Iteration 45, loss = 0.43041634
Iteration 46, loss = 0.42924970
Iteration 47, loss = 0.42943015
Iteration 48, loss = 0.42902500
Iteration 49, loss = 0.42916853
Iteration 50, loss = 0.42981624
Iteration 51, loss = 0.42873656
Iteration 52, loss = 0.42896619
Iteration 53, loss = 0.42937474
Iteration 54, loss = 0.42867270
Iteration 55, loss = 0.42960545
Iteration 56, loss = 0.42897219
Iteration 57, loss = 0.42904178
Iteration 58, loss = 0.42820685
Iteration 59, loss = 0.42910645
Iteration 60, loss = 0.42874855
Iteration 61, loss = 0.42805493
Iteration 62, loss = 0.42853651
Iteration 63, loss = 0.42815029
Iteration 64, loss = 0.42745896
Iteration 65, loss = 0.42872785
Iteration 66, loss = 0.42774735
Iteration 67, loss = 0.42767454
Iteration 68, loss = 0.42804134
Iteration 69, loss = 0.42777838
Iteration 70, loss = 0.42757742
Iteration 71, loss = 0.42800119
Iteration 72, loss = 0.42743239
Iteration 73, loss = 0.42712825
Iteration 74, loss = 0.42779465
Iteration 75, loss = 0.42737045
Iteration 76, loss = 0.42702446
Iteration 77, loss = 0.42717516
Iteration 78, loss = 0.42852058
Iteration 79, loss = 0.42784161
Iteration 80, loss = 0.42675858
Iteration 81, loss = 0.42753577
Iteration 82, loss = 0.42706585
Iteration 83, loss = 0.42772804
Iteration 84, loss = 0.42749716
Iteration 85, loss = 0.42653788
Iteration 86, loss = 0.42715447
Iteration 87, loss = 0.42646416
Iteration 88, loss = 0.42593534
Iteration 89, loss = 0.42634745
Iteration 90, loss = 0.42581725
Iteration 91, loss = 0.42596540
Iteration 92, loss = 0.42695601
Iteration 93, loss = 0.42595552
Iteration 94, loss = 0.42630278
Iteration 95, loss = 0.42603089
Iteration 96, loss = 0.42553029
Iteration 97, loss = 0.42577860
Iteration 98, loss = 0.42582862
Iteration 99, loss = 0.42538126
Iteration 100, loss = 0.42698085
Iteration 101, loss = 0.42533710
Iteration 102, loss = 0.42502812
Iteration 103, loss = 0.42632800
Iteration 104, loss = 0.42609978
Iteration 105, loss = 0.42555040
Iteration 106, loss = 0.42464214
Iteration 107, loss = 0.42508393
Iteration 108, loss = 0.42562175
Iteration 109, loss = 0.42571796
Iteration 110, loss = 0.42469363
Iteration 111, loss = 0.42507556
Iteration 112, loss = 0.42487105
Iteration 113, loss = 0.42415122
Iteration 114, loss = 0.42486775
Iteration 115, loss = 0.42575874
Iteration 116, loss = 0.42401184
Iteration 117, loss = 0.42504847
Iteration 118, loss = 0.42504910
Iteration 119, loss = 0.42469157
Iteration 120, loss = 0.42563376
Iteration 121, loss = 0.42476704
Iteration 122, loss = 0.42476364
Iteration 123, loss = 0.42501849
Iteration 124, loss = 0.42482010
Iteration 125, loss = 0.42434149
Iteration 126, loss = 0.42345264
Iteration 127, loss = 0.42516901
Iteration 128, loss = 0.42452124
Iteration 129, loss = 0.42459636
Iteration 130, loss = 0.42507301
Iteration 131, loss = 0.42349171
Iteration 132, loss = 0.42485698
Iteration 133, loss = 0.42383239
Iteration 134, loss = 0.42402621
Iteration 135, loss = 0.42337954
Iteration 136, loss = 0.42449205
Iteration 137, loss = 0.42463554
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
training finished.
training accuracy: 0.7951070336391437
number of correct predictions: 8799
validation accuracy: 0.7245553359683794
validation precision: 0.4329411764705882
validation recall: 0.5847457627118644
validation mcc: 0.32028601344842866
validation f1: 0.49752140603875616
validation confusion matrix: [[7143 2169]
 [1176 1656]]
